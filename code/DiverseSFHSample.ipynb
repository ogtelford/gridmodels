{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating 100,000 FSPS Spectra with Diverse SFHs\n",
    "\n",
    "Goal is to get a more thoroughly sampled manifold, with more diverse star formation histories spanning a wider range of mean ages...\n",
    "\n",
    "Updated 2017-02-07 to use zcontinuous=1 (vs. integer values for metallicity)\n",
    "\n",
    "Updated 2017-03-14 to add nebular emission (gas_logu fixed to default and gas_logz equal to logzsol) and allow more dust properties to vary (dust1 fixed to 2xdust2, and dust_index set equal to dust1_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# imports and plotting setup\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import fsps\n",
    "from astroML.plotting import setup_text_plots\n",
    "import h5py\n",
    "\n",
    "np.set_printoptions(suppress=True)\n",
    "setup_text_plots(fontsize=24)\n",
    "mpl.rc('xtick', labelsize=18)\n",
    "mpl.rc('ytick', labelsize=18)\n",
    "mpl.rc('font', size=24, family='serif', style='normal', variant='normal', stretch='normal', weight='bold')\n",
    "mpl.rc('legend', labelspacing=0.1, handlelength=2, fontsize=13)\n",
    "mpl.rc('axes', labelweight='black')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate random values of all parameters. Need to think more about what are appropriate distributions for each of these parameters -- just using uniform (either linear or log) sampling in each parameter for now..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# get 100,000 samples\n",
    "size=100000\n",
    "\n",
    "#sf_begin = np.random.uniform(low=0.0, high=12.2, size=size)\n",
    "logsf_begins = np.random.uniform(low=np.log10(0.1), high=np.log10(12.2), size=size)\n",
    "sf_begins = 10**logsf_begins\n",
    "As = 13.7 - sf_begins\n",
    "\n",
    "logtbursts = np.array([])\n",
    "for ii in range(size):\n",
    "    logtbursts = np.append(logtbursts, np.random.uniform(low=np.log10(sf_begins[ii]), high=np.log10(13.6)))\n",
    "tbursts = 10**logtbursts\n",
    "\n",
    "logfbursts = np.random.uniform(low=np.log10(0.01), high=np.log10(0.5), size=size)\n",
    "fbursts = 10**logfbursts\n",
    "\n",
    "logtaus = np.random.uniform(low=-0.5, high=1.5, size=size)\n",
    "taus = 10**logtaus\n",
    "tau_ages = As - taus * ( (1. - (As/taus + 1.) * np.exp(-As/taus)) / (1. - np.exp(-As/taus)) ) # mean ages given taus\n",
    "\n",
    "total_ages = (1-fbursts) * tau_ages + fbursts * (13.7 - tbursts)\n",
    "\n",
    "dusts = np.random.uniform(low=0.0, high=1.0, size=size)\n",
    "dust_slopes = np.random.uniform(low=-1.3, high=-0.3, size=size)\n",
    "\n",
    "zs = np.random.uniform(low=-1.5, high=0.2, size=size) #not an ideal distribution; will get a lot of low metallicities...\n",
    "\n",
    "#sigmas = np.random.uniform(low=0.0, high=300.0, size=size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n, bins, patches = plt.hist(total_ages, bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.max(sf_begins)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### now build the model spectra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "spectra = np.zeros((size, 4220)) #know there are 4220 steps in desired wavelength range\n",
    "mags = np.zeros((size, 5)) # save mags in 5 SDSS filters\n",
    "bands = fsps.find_filter('sdss') # u, g, i, r, z (NOTE SILLY ORDERING)\n",
    "ii = 0\n",
    "\n",
    "for sf_begin, tburst, fburst, tau, dust, dust_slope, z  in zip(sf_begins, tbursts, fbursts, taus, dusts, dust_slopes, zs):\n",
    "    sp = fsps.StellarPopulation(compute_vega_mags=False, sfh=4, sigma_smooth=100., dust_type=2,\n",
    "                                add_neb_emission=True, add_neb_continuum=True, sf_start=sf_begin, \n",
    "                                tburst=tburst, fburst=fburst, tau=tau, dust1=2*dust, dust2=dust,\n",
    "                                dust_index=dust_slope, dust1_index=dust_slope, zcontinuous=1,\n",
    "                                logzsol=z, gas_logz=z, gas_logu=-2.0)\n",
    "    wave, spec = sp.get_spectrum(tage=13.7, peraa=True)\n",
    "    wh = (wave < 7400.) * (wave > 3600.)\n",
    "    spectra[ii, :] = spec[wh]\n",
    "    mags[ii, :] = sp.get_mags(bands=fsps.find_filter('sdss'), tage=13.7)\n",
    "    ii += 1\n",
    "    if ii%500 == 0:\n",
    "        percent = ii/1000.\n",
    "        print \"%g percent complete\" % percent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### normalize the spectra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "norms = spectra.shape[1] / np.sum(spectra, axis=1)\n",
    "spectra_norm = spectra * norms[:,np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# quick sanity check\n",
    "plt.figure()\n",
    "plt.plot(wave[wh], spectra_norm[100])\n",
    "plt.plot(wave[wh], spectra_norm[1009])\n",
    "plt.plot(wave[wh], spectra_norm[6095])\n",
    "plt.plot(wave[wh], spectra_norm[9998])\n",
    "plt.plot(wave[wh], spectra_norm[50628])\n",
    "plt.plot(wave[wh], spectra_norm[82534])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### save spectra and parameters to HDF5 file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f = h5py.File('../data/1e5_spectra_diverseSFH_elines_17-03-14.hdf5','w')\n",
    "f.create_dataset('spectra', data=spectra_norm)\n",
    "f.create_dataset('wave', data=wave[wh])\n",
    "f.create_dataset('sdss_mags', data=mags)\n",
    "f.create_dataset('sf_begins', data=sf_begins)\n",
    "f.create_dataset('tbursts', data=tbursts)\n",
    "f.create_dataset('fbursts', data=fbursts)\n",
    "f.create_dataset('taus', data=taus)\n",
    "f.create_dataset('mean_ages', data=total_ages)\n",
    "f.create_dataset('zs', data=zs)\n",
    "f.create_dataset('dusts', data=dusts)\n",
    "f.create_dataset('dust_slopes', data=dust_slopes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f['spectra'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
